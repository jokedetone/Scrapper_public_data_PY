{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jokedetone/Scrapper_public_data_PY/blob/main/PYTHON_DATALCH_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSGw-xyWAhWn"
      },
      "source": [
        "# **FUNCIONA CON XPATH**\n",
        "\n",
        "Permite descargar los ZIPS de [**PGN PARAGUAY**](https://datos.hacienda.gov.py/data/pgn-gasto/descargas ).\n",
        "\n",
        "### **Realizado:**\n",
        "*   Descarga y organiza los ZIPS en carpetas individuales por año\n",
        "\n",
        "*   Extraer cada uno de los ZIPS dentro de sus respectivas carpetas y eliminar los ZIPS una vez que se cuente con el CSV.\n",
        "\n",
        "### **Falta:**\n",
        "*   Limpiar el dataset final\n",
        "\n",
        "*   Análisis exploratorio\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xqUawuU8fwS"
      },
      "outputs": [],
      "source": [
        "!apt-get update\n",
        "!apt install -y chromium-chromedriver\n",
        "!pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vt93P651AhWo"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "import os\n",
        "import time\n",
        "import requests\n",
        "import zipfile\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "# Set up Selenium in Colab\n",
        "options = Options()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome(options=options)\n",
        "\n",
        "# URL to scrape\n",
        "url = \"https://datos.hacienda.gov.py/data/pgn-gasto/descargas\"\n",
        "\n",
        "# Years we want to download and their respective folders\n",
        "target_years = {\n",
        "    '2019': '2019_data',\n",
        "    '2020': '2020_data',\n",
        "    '2021': '2021_data',\n",
        "    '2022': '2022_data',\n",
        "    '2023': '2023_data',\n",
        "    '2024': '2024_data',\n",
        "    '2025': '2025_data'\n",
        "}\n",
        "\n",
        "def setup_folders():\n",
        "    \"\"\"Create folders for each year if they don't exist\"\"\"\n",
        "    for folder in target_years.values():\n",
        "        os.makedirs(folder, exist_ok=True)\n",
        "    print(\"Created year-specific folders\")\n",
        "\n",
        "def extract_zip(zip_path, extract_to):\n",
        "    \"\"\"Extract a ZIP file to specified directory\"\"\"\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_to)\n",
        "        print(f\"  ✓ Extracted to {extract_to}\")\n",
        "        return True\n",
        "    except zipfile.BadZipFile:\n",
        "        print(f\"  ✗ Error: Bad ZIP file - {zip_path}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"  ✗ Extraction failed: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "    # Create folders first\n",
        "    setup_folders()\n",
        "\n",
        "    # Load the page\n",
        "    print(\"Loading page...\")\n",
        "    driver.get(url)\n",
        "    time.sleep(5)  # Wait for JavaScript to load completely\n",
        "\n",
        "    # Find all download links using XPath\n",
        "    download_links = driver.find_elements(\n",
        "        By.XPATH, \"//a[contains(translate(@href, 'ZIP', 'zip'), 'zip')]\"\n",
        "    )\n",
        "\n",
        "    if not download_links:\n",
        "        print(\"No ZIP download links found!\")\n",
        "    else:\n",
        "        print(f\"Found {len(download_links)} ZIP files. Filtering for target years...\")\n",
        "\n",
        "        downloaded_files = {year: 0 for year in target_years}\n",
        "        extracted_files = {year: 0 for year in target_years}\n",
        "\n",
        "        for link in download_links:\n",
        "            try:\n",
        "                # Get the download URL\n",
        "                zip_url = link.get_attribute('href')\n",
        "                filename = zip_url.split('/')[-1]\n",
        "\n",
        "                # Determine which year this file belongs to\n",
        "                file_year = None\n",
        "                for year in target_years:\n",
        "                    if year in filename:\n",
        "                        file_year = year\n",
        "                        break\n",
        "\n",
        "                if file_year:\n",
        "                    # Handle relative URLs\n",
        "                    if not zip_url.startswith('http'):\n",
        "                        zip_url = f\"https://datos.hacienda.gov.py{zip_url}\" if zip_url.startswith('/') else f\"{url}/{zip_url}\"\n",
        "\n",
        "                    folder_path = target_years[file_year]\n",
        "                    zip_path = os.path.join(folder_path, filename)\n",
        "\n",
        "                    print(f\"\\nProcessing {filename}:\")\n",
        "                    print(f\"- Downloading to {folder_path}...\")\n",
        "\n",
        "                    # Download the file\n",
        "                    with requests.get(zip_url, stream=True) as r:\n",
        "                        r.raise_for_status()\n",
        "                        with open(zip_path, 'wb') as f:\n",
        "                            for chunk in r.iter_content(chunk_size=8192):\n",
        "                                if chunk:\n",
        "                                    f.write(chunk)\n",
        "\n",
        "                    downloaded_files[file_year] += 1\n",
        "                    print(f\"  ✓ Download complete\")\n",
        "\n",
        "                    # Extract the ZIP file\n",
        "                    print(f\"- Extracting contents...\")\n",
        "                    if extract_zip(zip_path, folder_path):\n",
        "                        extracted_files[file_year] += 1\n",
        "\n",
        "                    # Optionally remove the ZIP after extraction (uncomment to enable)\n",
        "                    os.remove(zip_path)\n",
        "                    print(\"  ✓ Removed ZIP file after extraction\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"✗ Failed to process {filename}: {str(e)}\")\n",
        "\n",
        "        # Print download summary\n",
        "        print(\"\\n=== Download Summary ===\")\n",
        "        for year in target_years:\n",
        "            print(f\"{year}:\")\n",
        "            print(f\"  - Downloaded: {downloaded_files[year]} files\")\n",
        "            print(f\"  - Extracted: {extracted_files[year]} files\")\n",
        "\n",
        "        total_downloaded = sum(downloaded_files.values())\n",
        "        total_extracted = sum(extracted_files.values())\n",
        "        print(f\"\\nTotal: {total_downloaded} files downloaded, {total_extracted} files extracted\")\n",
        "\n",
        "finally:\n",
        "    driver.quit()\n",
        "    print(\"\\nProcess completed. You can find the files in their respective year folders.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rPuY9NPUlS8"
      },
      "outputs": [],
      "source": [
        "#filtrar descripcionEntidad 005-MINISTERIO DE DEFENSA NACIONAL\n",
        "\n",
        "def load_year_data(folder_path, year):\n",
        "    \"\"\"Load all CSV files from a year folder into a DataFrame,\n",
        "    combine them, filter by 'descripcionEntidad', and remove individual CSVs.\"\"\"\n",
        "    csv_files = glob(os.path.join(folder_path, \"*.csv\"))\n",
        "    if not csv_files:\n",
        "        print(f\"No CSV files found in {folder_path}\")\n",
        "        return None\n",
        "\n",
        "    print(f\"\\nLoading {len(csv_files)} CSV files for {year}:\")\n",
        "\n",
        "    year_dfs = []\n",
        "    for csv_file in csv_files:\n",
        "        try:\n",
        "            df = pd.read_csv(csv_file, encoding='ISO-8859-1', sep=',')\n",
        "            df['Year'] = year  # Add year column\n",
        "            year_dfs.append(df)\n",
        "            print(f\"  ✓ Loaded {os.path.basename(csv_file)} ({len(df)} rows)\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ✗ Failed to load {csv_file}: {str(e)}\")\n",
        "\n",
        "    if year_dfs:\n",
        "        combined_df = pd.concat(year_dfs, ignore_index=True)\n",
        "\n",
        "        # Filter the combined DataFrame\n",
        "        filtered_df = combined_df[combined_df['descripcionEntidad'] == '005-MINISTERIO DE DEFENSA NACIONAL']\n",
        "\n",
        "        combined_csv_path = os.path.join(folder_path, f\"combined_{year}.csv\")\n",
        "        filtered_df.to_csv(combined_csv_path, index=False)  # Save filtered DataFrame\n",
        "        print(f\"Saved filtered data to '{combined_csv_path}'\")\n",
        "\n",
        "        # Remove individual CSVs\n",
        "        for csv_file in csv_files:\n",
        "            os.remove(csv_file)\n",
        "            print(f\"Removed: {csv_file}\")\n",
        "\n",
        "        return filtered_df  # Return the filtered DataFrame\n",
        "    return None\n",
        "\n",
        "# Load and combine data\n",
        "print(\"\\nProcessing CSV files...\")\n",
        "yearly_dfs = {}  # Dictionary to store DataFrames for each year\n",
        "\n",
        "for year, folder in target_years.items():\n",
        "    year_df = load_year_data(folder, year)\n",
        "    if year_df is not None:\n",
        "        yearly_dfs[year] = year_df\n",
        "        print(f\"{year} DataFrame: {len(year_df)} rows\")\n",
        "\n",
        "# Combine all DataFrames\n",
        "if yearly_dfs:\n",
        "    combined_df = pd.concat(yearly_dfs.values(), ignore_index=True)\n",
        "    print(f\"\\nFinal Combined DataFrame: {len(combined_df)} rows\")\n",
        "\n",
        "    # Save to CSV\n",
        "    combined_df.to_csv('PRESU_2019-2025_COMBI.csv', index=False)\n",
        "    print(\"\\nSaved combined data to 'PRESU_2019-2025_COMBI.csv'\")\n",
        "else:\n",
        "    print(\"No data was loaded from any year\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbfcW2QZWjV6"
      },
      "source": [
        "# VERSION FINAL DE LA EXTRACCIÓN DE COTIZACION\n",
        "#### DESCRIPCIÓN\n",
        "\n",
        "*   Realiza la extracción de los datos desde el año 2019 hasta el 2025\n",
        "*   La tabla de cotizaciones desde el mes de Enero de 2019 hasta el 16-05-2019 no cuenta con el tfoot en el que se coloca el cierre del día para la compra como para la venta. A partir del siguiente día hábil, se cuenta con esa información directamente en el tfoot de la tabla.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0zPw5h0QAPD"
      },
      "outputs": [],
      "source": [
        "# Script para extraer datos de cotizaciones del Banco Central del Paraguay\n",
        "# URL: https://www.bcp.gov.py/webapps/web/cotizacion/referencial-fluctuante\n",
        "\n",
        "# Instalar las dependencias necesarias\n",
        "!pip install selenium\n",
        "!pip install beautifulsoup4\n",
        "!pip install pandas\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.support.ui import Select\n",
        "import os\n",
        "from datetime import datetime\n",
        "# Configure Chrome options for Colab\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument(\"--headless\")  # Run in headless mode\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "# Initialize the WebDriver\n",
        "driver = webdriver.Chrome(options=chrome_options)\n",
        "\n",
        "# Access the webpage\n",
        "url = \"https://www.bcp.gov.py/webapps/web/cotizacion/referencial-fluctuante\"\n",
        "driver.get(url)\n",
        "print(f\"Accessing URL: {url}\")\n",
        "\n",
        "# Wait for the page to load\n",
        "wait = WebDriverWait(driver, 10)\n",
        "print(\"Waiting for the page to load...\")\n",
        "try:\n",
        "    # Wait for the calendar UI to appear\n",
        "    wait.until(\n",
        "        EC.presence_of_element_located((By.XPATH, \"//div[@id='ui-datepicker-div']\"))\n",
        "    )\n",
        "    print(\"Datepicker UI detected successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to detect the datepicker: {str(e)}\")\n",
        "    driver.quit()\n",
        "    exit()\n",
        "# Hardcoded start year\n",
        "start_year = 2019\n",
        "\n",
        "# Get the current year dynamically\n",
        "current_year = datetime.now().year\n",
        "\n",
        "# Get month names in Spanish for filenames\n",
        "month_names = [\n",
        "    \"Ene\", \"Feb\", \"Mar\", \"Abr\", \"May\", \"Jun\",\n",
        "    \"Jul\", \"Ago\", \"Sep\", \"Oct\", \"Nov\", \"Dic\"\n",
        "]\n",
        "\n",
        "# Define the cutoff date\n",
        "cutoff_date = datetime(2019, 5, 16)\n",
        "\n",
        "# Loop through all years from start_year to current_year\n",
        "for year in range(start_year, current_year + 1):  # Include the current year\n",
        "    print(f\"Processing year: {year}\")\n",
        "    for month_index in range(12):  # Loop through all months (0 to 11)\n",
        "        try:\n",
        "            # Open the calendar and select the year\n",
        "            print(\"Searching for available days in the calendar...\")\n",
        "            calendar_trigger_element = wait.until(EC.element_to_be_clickable((By.ID, \"calendar\")))\n",
        "            driver.execute_script(\"document.getElementById('calendar').click()\")\n",
        "            print(\"Clicked on the calendar. The datepicker should now be visible.\")\n",
        "\n",
        "            # Select the year\n",
        "            year_dropdown = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, \"ui-datepicker-year\")))\n",
        "            year_dropdown.click()\n",
        "            select_year = Select(year_dropdown)\n",
        "            select_year.select_by_visible_text(str(year))\n",
        "            print(f\"Selected year {year}.\")\n",
        "\n",
        "            # Select the month\n",
        "            month_dropdown = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, \"ui-datepicker-month\")))\n",
        "            month_dropdown.click()\n",
        "            select_month = Select(month_dropdown)\n",
        "            select_month.select_by_index(month_index)\n",
        "            print(f\"Selected month: {month_names[month_index]}.\")\n",
        "\n",
        "            # Find available days\n",
        "            dias_disponibles = driver.find_elements(\n",
        "                By.XPATH,\n",
        "                \"//div[@id='ui-datepicker-div']//table[@class='ui-datepicker-calendar']//td[@title='Available']//a\"\n",
        "            )\n",
        "\n",
        "            if not dias_disponibles:\n",
        "                print(f\"No available days found for {month_names[month_index]} {year}. Skipping...\")\n",
        "                continue\n",
        "\n",
        "            print(f\"Found {len(dias_disponibles)} available days in {month_names[month_index]} {year}.\")\n",
        "\n",
        "            # Initialize a list to store all data for the current month\n",
        "            datos_cotizaciones = []\n",
        "\n",
        "            # Loop through all available days in the current month\n",
        "            for day_index in range(len(dias_disponibles)):\n",
        "                try:\n",
        "                    # Reopen the calendar and re-select the year and month\n",
        "                    calendar_trigger_element = wait.until(EC.element_to_be_clickable((By.ID, \"calendar\")))\n",
        "                    driver.execute_script(\"document.getElementById('calendar').click()\")\n",
        "                    print(\"Reopened the calendar.\")\n",
        "\n",
        "                    # Select the year\n",
        "                    year_dropdown = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, \"ui-datepicker-year\")))\n",
        "                    year_dropdown.click()\n",
        "                    select_year = Select(year_dropdown)\n",
        "                    select_year.select_by_visible_text(str(year))\n",
        "                    print(f\"Selected year {year}.\")\n",
        "\n",
        "                    # Select the month\n",
        "                    month_dropdown = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, \"ui-datepicker-month\")))\n",
        "                    month_dropdown.click()\n",
        "                    select_month = Select(month_dropdown)\n",
        "                    select_month.select_by_index(month_index)\n",
        "                    print(f\"Selected month: {month_names[month_index]}.\")\n",
        "\n",
        "                    # Re-fetch the list of available days\n",
        "                    dias_disponibles = driver.find_elements(\n",
        "                        By.XPATH,\n",
        "                        \"//div[@id='ui-datepicker-div']//table[@class='ui-datepicker-calendar']//td[@title='Available']//a\"\n",
        "                    )\n",
        "\n",
        "                    # Click on the current day\n",
        "                    day = dias_disponibles[day_index]\n",
        "                    day.click()\n",
        "                    print(f\"Clicked on day {day_index + 1}.\")\n",
        "\n",
        "                    # Wait for the table to load\n",
        "                    a = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"table.table\")))\n",
        "\n",
        "                    fecha_element = driver.find_element(By.XPATH, \"//*[@id='dp_cotizacion']\")\n",
        "                    value_date = fecha_element.get_attribute(\"value\")\n",
        "\n",
        "                    # Parse the current date\n",
        "                    current_date = datetime.strptime(value_date, \"%d/%m/%Y\")\n",
        "\n",
        "                    # Extract data based on the cutoff date\n",
        "                    if current_date < cutoff_date:\n",
        "                        # Extract data from the last row\n",
        "                        a= wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"table.table\")))\n",
        "                        rows = a.find_elements(By.XPATH, \"./tbody/tr\")\n",
        "                        last_row = rows[-1]\n",
        "\n",
        "\n",
        "                        cells = last_row.find_elements(By.TAG_NAME, \"td\")\n",
        "                        if cells:\n",
        "                            fecha = value_date\n",
        "                            compra = cells[1].text.strip()\n",
        "                            venta = cells[2].text.strip()\n",
        "                            print(f\"Extracted data from last row for {fecha}: Compra={compra}, Venta={venta}\")\n",
        "                        else:\n",
        "                            print(\"No data found in the last row.\")\n",
        "                        datos_cotizaciones.append(\n",
        "                            {\"Fecha\": fecha, \"Compra\": compra, \"Venta\": venta}\n",
        "                        )\n",
        "                    else:\n",
        "\n",
        "                        tfoot = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"table.table tfoot\")))\n",
        "                        rows = tfoot.find_elements(By.XPATH, \"./tr\")\n",
        "                        # Extract data from all rows\n",
        "                        for row in rows:\n",
        "                            cells = row.find_elements(By.TAG_NAME, \"th\")\n",
        "                            if cells:\n",
        "                                fecha = value_date\n",
        "                                compra = cells[1].text.strip()\n",
        "                                venta = cells[2].text.strip()\n",
        "                                print(f\"Extracted data for {fecha}: Compra={compra}, Venta={venta}\")\n",
        "\n",
        "                            datos_cotizaciones.append(\n",
        "                                {\"Fecha\": fecha, \"Compra\": compra, \"Venta\": venta}\n",
        "                            )\n",
        "                except Exception as e:\n",
        "                    # Handle exception and add a placeholder entry\n",
        "                    print(f\"Exception occurred for day {day_index + 1}: {str(e)}\")\n",
        "                    fecha_element = driver.find_element(By.XPATH, \"//*[@id='dp_cotizacion']\")\n",
        "                    value_date = fecha_element.get_attribute(\"value\")\n",
        "                    datos_cotizaciones.append(\n",
        "                        {\"Fecha\": value_date, \"Compra\": \"N/A\", \"Venta\": \"N/A\"}\n",
        "                    )\n",
        "                    continue\n",
        "\n",
        "            # Save all data for the current month\n",
        "            if datos_cotizaciones:\n",
        "                # Create folder if it doesn't exist\n",
        "                folder_name = \"cotizaciones_bcp\"\n",
        "                if not os.path.exists(folder_name):\n",
        "                    os.makedirs(folder_name)\n",
        "                    print(f\"Created folder: {folder_name}\")\n",
        "\n",
        "                # Create the filename and full file path\n",
        "                filename = f\"cotizacion_{year}_{month_index}_{month_names[month_index]}.csv\"\n",
        "                filepath = os.path.join(folder_name, filename)\n",
        "\n",
        "                # Save the CSV file\n",
        "                pd.DataFrame(datos_cotizaciones).to_csv(filepath, index=False)\n",
        "                print(f\"File saved: {filepath}\")\n",
        "            else:\n",
        "                print(f\"No data available to save for {month_names[month_index]} {year}.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Exception occurred for {month_names[month_index]} {year}: {str(e)}\")\n",
        "            continue\n",
        "driver.quit()"
      ],
      "metadata": {
        "id": "uHBpJh4nP0Ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DESCARGAR TODOS LOS ARCHIVOS DE LA CARPETA COTIZACIONES_BCP\n"
      ],
      "metadata": {
        "id": "SrKR5Ruexr3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "carpeta = \"cotizaciones_bcp\"\n",
        "\n",
        "if os.path.exists(carpeta):\n",
        "    print(f\"Comprimiendo la carpeta '{carpeta}' para su descarga...\")\n",
        "    # Comprimir la carpeta\n",
        "    !zip -r /content/{carpeta}.zip /content/{carpeta}\n",
        "    print(f\"Carpeta '{carpeta}' comprimida exitosamente. Iniciando descarga...\")\n",
        "    # Descargar el archivo ZIP\n",
        "    files.download(f\"{carpeta}.zip\")\n",
        "else:\n",
        "    print(f\"La carpeta '{carpeta}' no existe.\")"
      ],
      "metadata": {
        "id": "1gYxWpaExygv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AGREGAR TODOS LOS CSV AL DATAFRAME"
      ],
      "metadata": {
        "id": "lk9Lpkm0yLJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "# Define the folder containing the CSV files\n",
        "carpeta = \"cotizaciones_bcp\"\n",
        "\n",
        "# List all files in the folder and filter for those ending with .csv\n",
        "archivos_csv = [f for f in os.listdir(carpeta) if f.endswith(\".csv\")]\n",
        "\n",
        "# List to store the DataFrames from each file\n",
        "dataframes = []\n",
        "\n",
        "print(f\"Found {len(archivos_csv)} CSV files in '{carpeta}'. Loading...\")\n",
        "\n",
        "# Read and append each CSV file to the list\n",
        "for archivo in archivos_csv:\n",
        "    ruta = os.path.join(carpeta, archivo)\n",
        "    try:\n",
        "        # Try reading with UTF-8 encoding first\n",
        "        df = pd.read_csv(ruta, encoding=\"utf-8\")\n",
        "        print(f\"  ✓ Successfully read {archivo} with utf-8 encoding.\")\n",
        "    except UnicodeDecodeError:\n",
        "        # If UTF-8 fails, try latin1 encoding\n",
        "        try:\n",
        "            df = pd.read_csv(ruta, encoding=\"latin1\")\n",
        "            print(f\"  ✓ Successfully read {archivo} with latin1 encoding.\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ✗ Error reading {archivo} with both utf-8 and latin1: {e}\")\n",
        "            continue # Skip this file if both encodings fail\n",
        "\n",
        "    # Add the DataFrame to the list\n",
        "    dataframes.append(df)\n",
        "\n",
        "# Unir all DataFrames in the list\n",
        "if dataframes:\n",
        "    df_total = pd.concat(dataframes, ignore_index=True)\n",
        "    print(f\"\\nAll CSV files combined into a single DataFrame with {len(df_total)} rows.\")\n",
        "\n",
        "    # Display the first few rows and information about the combined DataFrame\n",
        "    print(\"\\n--- First 5 rows of the combined DataFrame ---\")\n",
        "    print(df_total.head())\n",
        "\n",
        "    print(\"\\n--- Info about the combined DataFrame ---\")\n",
        "    df_total.info()\n",
        "\n",
        "else:\n",
        "    print(\"\\nNo CSV files were successfully loaded.\")\n",
        "# Define the name for the output CSV file\n",
        "output_filename = \"combined_cotizaciones.csv\"\n",
        "# Save the combined DataFrame to a CSV file\n",
        "df_total.to_csv(output_filename, index=False)"
      ],
      "metadata": {
        "id": "-p3-tbwMyRZf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}